# üîÑ Workflows Recommand√©s

Workflows √©prouv√©s pour diff√©rents besoins et profils.

## üìÖ Workflow Quotidien (DevOps/SRE)

**Temps**: 5-10 minutes
**Objectif**: S√©curit√© et disponibilit√©

```bash
#!/bin/bash
# daily-check.sh

echo "=== Audit Quotidien GCP ==="
date

# 1. S√©curit√© critique
echo "\nüîê Scan s√©curit√©..."
./scripts/scan-public-buckets.sh
./scripts/audit-service-account-keys.sh --days 90

# 2. Backups
echo "\nüíæ V√©rification backups..."
./scripts/audit-database-backups.sh

# 3. Quotas
echo "\nüìä Check quotas..."
./scripts/check-quotas.sh --threshold 80

# Alerter si probl√®mes
echo "\n‚úÖ Audit termin√©"
```

**Automatisation**:
```bash
# Crontab: tous les jours √† 8h
0 8 * * * /path/to/daily-check.sh | mail -s "GCP Daily Check" devops@company.com
```

## üìÜ Workflow Hebdomadaire (Security Team)

**Temps**: 20-30 minutes
**Objectif**: Audit de s√©curit√© complet

```bash
#!/bin/bash
# weekly-security-audit.sh

REPORT_DIR="./security-reports"
DATE=$(date +%Y%m%d)
mkdir -p "$REPORT_DIR"

echo "=== Audit S√©curit√© Hebdomadaire ==="

# 1. Cl√©s de service accounts
echo "1/4 Audit cl√©s SA..."
./scripts/audit-service-account-keys.sh --json > "$REPORT_DIR/sa-keys-$DATE.json"

# 2. Buckets publics
echo "2/4 Scan buckets..."
./scripts/scan-public-buckets.sh --json > "$REPORT_DIR/public-buckets-$DATE.json"

# 3. Permissions IAM
echo "3/4 Audit IAM..."
./scripts/audit-iam-permissions.sh --json > "$REPORT_DIR/iam-$DATE.json"

# 4. Bases de donn√©es
echo "4/4 Check Cloud SQL..."
./scripts/list-cloud-sql-instances.sh --json > "$REPORT_DIR/cloudsql-$DATE.json"

# Analyse avec jq
echo "\nüìä Analyse..."
echo "Cl√©s critiques: $(cat $REPORT_DIR/sa-keys-$DATE.json | jq '.summary.critical_risk')"
echo "Buckets publics: $(cat $REPORT_DIR/public-buckets-$DATE.json | jq '.summary.public_buckets')"
echo "Owners total: $(cat $REPORT_DIR/iam-$DATE.json | jq '.summary.owner_count')"

echo "\n‚úÖ Rapport sauvegard√© dans $REPORT_DIR"
```

## üìä Workflow Mensuel (FinOps)

**Temps**: 1-2 heures
**Objectif**: Optimisation des co√ªts

### Phase 1: Analyse (Semaine 1)

```bash
#!/bin/bash
# monthly-cost-analysis.sh

echo "=== Analyse Co√ªts Mensuelle ==="

# 1. Inventaire complet
./scripts/list-all-vms.sh --json > inventory-vms.json
./scripts/list-cloud-sql-instances.sh --json > inventory-sql.json
./scripts/list-gke-clusters.sh --json > inventory-gke.json

# 2. D√©tection gaspillage
./scripts/find-unused-resources.sh --days 30 --json > waste.json
./scripts/audit-container-images.sh --days 90 --json > old-images.json

# 3. Opportunit√©s d'optimisation
./scripts/compare-vm-rightsizing.sh --days 30 --json > rightsizing.json
./scripts/check-preemptible-candidates.sh --json > spot-candidates.json
./scripts/analyze-committed-use.sh --json > cud-analysis.json

# 4. Anomalies
./scripts/track-cost-anomalies.sh --threshold 20 --json > anomalies.json

# R√©sum√©
echo "\nüí∞ R√âSUM√â √âCONOMIES POTENTIELLES:"
echo "VMs unused: \$$(cat waste.json | jq '.summary.total_unused_ips * 7') (IPs statiques)"
echo "Rightsizing: \$$(cat rightsizing.json | jq '.summary.potential_monthly_savings_usd')"
echo "Spot VMs: \$$(cat spot-candidates.json | jq '.summary.potential_monthly_savings')"
echo "Images cleanup: \$$(cat old-images.json | jq '.summary.total_size_gb / 10')"
```

### Phase 2: Action (Semaine 2-3)

Cr√©er des tickets pour chaque optimisation:

```markdown
## Ticket: Cleanup IPs Statiques Inutilis√©es

**Impact**: $210/mois √©conomis√©s
**Effort**: 1h
**Risque**: Faible

**Actions**:
1. V√©rifier avec teams que IPs non utilis√©es
2. Lib√©rer via: `gcloud compute addresses delete IP_NAME --region=REGION`
3. V√©rifier pas d'impact
```

### Phase 3: Reporting (Semaine 4)

```bash
# G√©n√®re un rapport ex√©cutif
cat > executive-report.md << EOF
# Rapport Optimisation Co√ªts - $(date +"%B %Y")

## üìä M√©triques

- **Co√ªts actuels estim√©s**: \$XX,XXX/mois
- **√âconomies identifi√©es**: \$X,XXX/mois (XX%)
- **√âconomies r√©alis√©es**: \$XXX/mois

## üéØ Actions R√©alis√©es

1. ‚úÖ Suppression 15 IPs statiques inutilis√©es (-\$105/mois)
2. ‚úÖ Rightsizing 8 VMs sur-provisionn√©es (-\$400/mois)
3. ‚úÖ Migration 12 VMs vers Spot (-\$1,200/mois)
4. ‚è≥ CUD 1 an en cours d'approbation (-\$3,500/mois estim√©)

## üìà Tendances

- Croissance co√ªts: +15% vs mois dernier
- Principale cause: Nouveau cluster GKE (data-analytics)
- Action: Monitorer de pr√®s

## üéØ Prochaines √âtapes

1. Finaliser CUD
2. Auditer containers images
3. √âvaluer Cloud Run vs GKE pour microservices
EOF
```

## üö® Workflow Incident (Data Leak)

**Si `scan-public-buckets.sh` trouve des buckets publics:**

### R√©ponse Imm√©diate (< 1h)

```bash
# 1. Identifier le bucket
BUCKET_NAME="bucket-public-detecte"

# 2. V√©rifier le contenu
gsutil ls -r gs://$BUCKET_NAME | head -20

# 3. Retirer acc√®s public IMM√âDIATEMENT
gsutil iam ch -d allUsers gs://$BUCKET_NAME
gsutil iam ch -d allAuthenticatedUsers gs://$BUCKET_NAME

# 4. V√©rifier
gsutil iam get gs://$BUCKET_NAME | grep -i "allUsers\|allAuthenticatedUsers"

# Si vide: OK, acc√®s public retir√©
```

### Investigation (< 4h)

```bash
# 5. Qui a rendu ce bucket public ?
gcloud logging read "resource.type=gcs_bucket AND \
  resource.labels.bucket_name=$BUCKET_NAME AND \
  protoPayload.methodName=storage.setIamPermissions" \
  --limit=50 --format=json

# 6. Quand ?
# Regarder les timestamps dans les logs

# 7. Quoi est expos√© ?
gsutil ls -L gs://$BUCKET_NAME > bucket-inventory.txt

# 8. Qui a acc√©d√© aux donn√©es ?
# Logs d'acc√®s (si activ√©s)
gsutil logging get gs://$BUCKET_NAME
```

### Post-Mortem (< 24h)

1. **Documenter** l'incident
2. **Notifier** CISO / DPO si donn√©es sensibles
3. **Corriger** processus (IAM policy, alerting)
4. **Tester** d√©tection (refaire l'incident en dev)

## üìà Workflow Scaling Event

**Avant un √©v√©nement majeur (Black Friday, lancement produit):**

### Pr√©paration (J-7)

```bash
# 1. Check quotas actuels
./scripts/check-quotas.sh --threshold 60

# 2. Calculer besoins
# Trafic attendu: 10x normal
# Donc: demander quotas * 10

# 3. Demander augmentations
# IAM & Admin > Quotas dans Console GCP
# D√©lai: 2-5 jours ouvr√©s

# 4. V√©rifier backup/DR
./scripts/audit-database-backups.sh
```

### Pendant l'√©v√©nement (J)

```bash
# Monitoring continu
watch -n 300 './scripts/check-quotas.sh --threshold 70'

# Si quota critique (>90%):
# - Scaler horizontalement si possible
# - Demander augmentation urgente
```

### Post-√©v√©nement (J+1)

```bash
# 1. Analyse co√ªts
./scripts/track-cost-anomalies.sh

# 2. Rightsizing
./scripts/compare-vm-rightsizing.sh

# 3. Cleanup
./scripts/find-unused-resources.sh --days 1
```

## üîÑ Workflow CI/CD Integration

### GitLab CI Example

```yaml
# .gitlab-ci.yml
gcp-audit:
  stage: audit
  image: google/cloud-sdk:alpine
  script:
    - gcloud auth activate-service-account --key-file=$GCP_SA_KEY
    - cd carnet
    - ./scripts/scan-public-buckets.sh --json > buckets.json
    - ./scripts/audit-service-account-keys.sh --json > sa-keys.json
    - |
      if [ $(cat buckets.json | jq '.summary.public_buckets') -gt 0 ]; then
        echo "‚ùå √âCHEC: Buckets publics d√©tect√©s!"
        exit 1
      fi
    - |
      if [ $(cat sa-keys.json | jq '.summary.critical_risk') -gt 0 ]; then
        echo "‚ö†Ô∏è WARNING: Cl√©s critiques d√©tect√©es"
      fi
  artifacts:
    reports:
      junit: audit-report.xml
    paths:
      - buckets.json
      - sa-keys.json
  only:
    - schedules
```

### GitHub Actions Example

```yaml
# .github/workflows/gcp-audit.yml
name: GCP Security Audit
on:
  schedule:
    - cron: '0 8 * * 1' # Lundi 8h
  workflow_dispatch:

jobs:
  audit:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - uses: google-github-actions/setup-gcloud@v1
        with:
          service_account_key: ${{ secrets.GCP_SA_KEY }}

      - name: Security Scan
        run: |
          chmod +x scripts/*.sh
          ./scripts/scan-public-buckets.sh
          ./scripts/audit-service-account-keys.sh

      - name: Upload Results
        uses: actions/upload-artifact@v3
        with:
          name: audit-results
          path: '*.json'
```

## üì± Workflow Alerting (Slack)

```bash
#!/bin/bash
# slack-alert.sh

WEBHOOK_URL="https://hooks.slack.com/services/YOUR/WEBHOOK/URL"

# Ex√©cute audit
PUBLIC_BUCKETS=$(./scripts/scan-public-buckets.sh --json | jq '.summary.public_buckets')

if [ "$PUBLIC_BUCKETS" -gt 0 ]; then
    curl -X POST $WEBHOOK_URL -H 'Content-type: application/json' -d '{
      "text": "üö® ALERTE GCP S√âCURIT√â",
      "attachments": [{
        "color": "danger",
        "fields": [{
          "title": "Buckets Publics D√©tect√©s",
          "value": "'"$PUBLIC_BUCKETS"' bucket(s) sont publiquement accessibles",
          "short": false
        }]
      }]
    }'
fi
```

## üí° Tips & Astuces

### Combiner plusieurs scripts

```bash
# Audit complet en une commande
for script in audit-service-account-keys scan-public-buckets check-quotas; do
    echo "Running $script..."
    ./scripts/$script.sh
done
```

### Filtrer avec jq

```bash
# Projets de production uniquement
./scripts/list-gcp-projects-json.sh | jq '.projects[] | select(.name | contains("prod"))'

# VMs co√ªteuses (>100$/mois)
./scripts/list-all-vms.sh --json | jq '.vms[] | select(.estimated_monthly_cost_usd > 100)'
```

### Comparaisons temporelles

```bash
# Sauvegarder snapshot
./scripts/list-all-vms.sh --json > vms-$(date +%Y%m%d).json

# 30 jours plus tard, comparer
diff <(jq '.summary' vms-20241101.json) <(jq '.summary' vms-20241201.json)
```

---

[‚¨ÖÔ∏è Quick Start](Quick-Start.md) | [üè† Wiki Home](HOME.md) | [‚û°Ô∏è Automation](Automation.md)
